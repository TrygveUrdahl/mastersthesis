\chapter{Neural Networks}
\label{sec:ml}


\section{Components of a Neural Network}
Input layer, hidden layers, output layer. 

Terms:
\begin{itemize}
    \item Layer.
    \item Neuron (perceptron).
    \item Activation function.
    \item Feature map.
    \item 
\end{itemize}

\section{Neural Network Types}


\subsection{Artificial Neural Network}
Linear function $ax+b$, and a non-linear activation function $\sigma$. 

Affine transformations and pointwise nonlinearities which are smooth Lipschitz functions (such as sigmoid, tanh, elu, softplus, etc.). 

\subsection{Convolutional Neural Network}
Convolutional kernels. Useful for image processing. Extract spatial information, context. 

\subsection{Encoder-Decoder Network}
Downscaling and upscaling between layers, and skip connections (for U-net, but not actually in encoder-decoder networks). % https://www.researchgate.net/post/Are_U-net_and_encoder-decoder_network_the_same 

\subsection{Generative Adversarial Network}
Learn probability distribution and generate random sample from learned distributiom. 
GAN based on game theory instead of optimization. 

\section{Training a Neural Network}


\subsection{Loss Functions}
MSE, MAE, LogCosh, VGG, Adversarial, 

\subsection{Backpropagation}

\subsection{Optimizers}

\subsubsection{Stochastic Gradient Descent}


\subsubsection{ADAM}

