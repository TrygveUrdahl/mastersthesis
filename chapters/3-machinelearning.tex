\chapter{Machine Learning}
\label{sec:ml}
The term \glsfirst{ml} was coined by Arthur Samuel in \citeyear{samuelmachinelearning} \cite{samuelmachinelearning}. An \gls{ml} algorithm builds a model based on a dataset, intended to make predictions or classifications without being explicitly programmed how to do so. 

Whereas some problems can easily be solved by programming an explicit algorithm (e.g. sorting a list, or \gls{fbp} reconstruction), there are many cases where an exact algorithm fails to provide adequate solutions to the problem. A typical example is to filter out spam emails from an email inbox. The content and structure of the spam emails vary sufficiently to prevent filtering them with "hardcoded" rules, as in conventional algorithms. This is where \gls{ml} comes in: an \gls{ml} model can be trained to discern differences in a dataset without being explicitly told what to look for. So long as there is a sufficient amount of data to train the model with, it may be able to find a pattern in the data and thereby predict or classify new data, or augment or enhance the data \cite[2-4]{Alpaydin10}. 

There are many different \gls{ml} algorithms, however in this thesis, only the class of \textit{neural networks} will be discussed and the focus will be on \textit{supervised learning}. 

This chapter contains a brief introduction to neural networks and their basic components, an explanation of what a \glsfirst{cnn} is, a description of encoder-decoder networks, and an introduction to \glspl{gan}, before covering the basics of how a neural network is trained and giving an overview of some common loss functions used for this process. 

\section{Components of a Neural Network}
\label{sec:ml:componentsofaneuralnetwork}
Neural networks are computing systems that are designed to learn in ways similar to the human brain by being exposed to large amounts of data, and attempting to find some inherent pattern or system to the data. 

Neural networks were initially designed to simulate the human brain and how it learns and adapts to new information \cite{McCulloch1943}. Because of this, the basic building block of a neural network is called a neuron. Several neurons build up a layer, and several layers build up a neural network. Neurons in different layers have connections to each other (i.e. neurons in layer 1 are connected to neurons in layer 2), these connections have weights, and each neuron has a bias. A simple schematic of this is given in \cref{fig:neuralnetwork}. The value of a neuron is a real number and can be given as \cite[81]{Wang2003}
\begin{equation}
    \label{eq:neuron}
    Y_{k} = \sigma\left(\sum_{j=0}^{m}w_{kj}x_j + \lambda_k \right),
\end{equation}
where $k$ refers to which neuron it is, $m$ is the number of inputs to the neuron, $w_{kj}$ is the weight of connection $j$, $x_j$ is the output value of neuron $j$ into neuron $k$, $\lambda_k$ is a bias term, and $\sigma$ is the activation (or transfer) function, which will be introduced later. It is thus a weighted sum of the values of the neurons in the previous layer (or more precisely, of all the input neurons to a given neuron, which often is the previous layer) and the neuron's own bias, passed through an activation function. Note that this describes a simple fully connected feedforward \gls{ann}, more precisely a \textit{multilayer perceptron}, and other types of neural networks may contain other types of layers \cite{Wang2003}. 

\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.8\textwidth]{figures/neuralnetwork.pdf}
    \caption[Illustration of a neural network]{Illustration of a neural network. Each circle represents a neuron, the solid arrows represent connections between neurons, and the dotted arrows represent input and output channels. The dimensions of the network parameters are denoted as $W_n$, where $n$ refers to the layer the parameters input into. This network specifically is a fully connected feedforward \gls{ann}, also known as a multi-layer perceptron, with one hidden layer. }
    \label{fig:neuralnetwork}
\end{figure}

The activation function, also known as the transfer function, is denoted as $\sigma$. Its purpose is to bound the value of a neuron so that the network does not diverge during training because of neurons with diverging values \cite[81]{Wang2003}. Furthermore, the activation function is used to introduce nonlinearity to the network,\footnote{For this reason, the identity activation function $f(x)=x$ generally performs poorly.} and it can be shown that a two-layer deep neural network with a nonlinear activation function is a \textit{universal function approximator}, meaning it can approximate any function mapping between two Euclidean spaces \cite{Cybenko1989}. There are many different activation functions, and some examples are presented in \cref{tab:activationfunctions} and plotted in \cref{fig:activationfunctions}.

\begin{table}[htbp]
    \centering
    \caption[Activation functions for neural networks]{Overview of some of the commonly used activation functions in neural networks. }
    \label{tab:activationfunctions}
    \begin{tabular}{ll}
    \hline
    Name & Function, $f(x)$ \\
    \hhline{==}
    Identity & $x$ \\
    Rectified Linear Unit (ReLU) & $\max\left(0, x\right)$ \\
    Leaky Rectified Linear Unit (LReLU) & $\max\left(\alpha x, x\right), \alpha\in[0,1]$ \\
    Logistic/soft step & $\frac{1}{1+e^{-x}}$  \\
    tanh & $\frac{e^x - e^{-x}}{e^x + e^{-x}}$ \\
    Softplus & $\ln\left(1+e^x\right)$ \\
    \hline
    \end{tabular}
\end{table}

\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.8\textwidth]{figures/activationfunctions.pdf}
    \caption[Activation functions for neural networks]{Plot showing a selection of activation functions for $x\in[-2,2]$. Note that identity, ReLU, and LReLU are overlapping for $x\in[0,2]$. See \cref{tab:activationfunctions} for definitions of the functions. }
    \label{fig:activationfunctions}
\end{figure}

The output of a neural network can be defined to be any shape (e.g. a vector, or matrix). In \cref{fig:neuralnetwork} the output is a single value, however it could just as well have been defined as a vector. If the output is a single value it can for instance be interpreted as a probability, however if it is a vector of length $n$ it can be seen as $n$ probabilities of different events or features. The output of a neural network is often called a feature map, because it can be seen as a mapping of the features of the input data. 

For example, if a neural network is trained with a dataset containing images of handwritten digits $0-9$, an output with a size of $10$ could contain probabilities of a given image containing a specific digit where each output value is the probability of one digit. One well-known dataset that is often used for this exact problem is the MNIST dataset \cite{mnist}.


\section{Neural Network Types}
There are many different types of neural networks that are suited for different problems. Here, a selection of types that lead up to the \gls{gan} structure used in this thesis will be introduced. 

\subsection{Convolutional Neural Network}
A \glsfirst{cnn} builds upon the structure of the \gls{ann}, however it adds a new type of layer: the convolutional layer. Instead of containing a set of neurons, this layer contains one (or more) convolutional kernel(s), and performs a convolution of the input to the layer, with the kernel(s). This type of network was first introduced in \citeyear{lecun1999object},\footnote{There is some disagreement around whether the paper by LeCun in \citeyear{lecun1999object} \cite{lecun1999object} was truly the introduction of \gls{cnn}s, however it is often seen as it. } and has shown to perform well for many different image related tasks \cite{lecun1999object,alexnet}. The convolution operation allows the network to utilize 2D information by performing 2D convolutions.\footnote{Likewise higher-dimensional information may be used by performing higher-dimensional convolutions \cite{8353466}. }

The discrete convolution operator is defined as \cite[899-901]{cormenalgorithms}
\begin{equation}
    \label{eq:convolution}
    g(x,y) = \omega \ast f(x,y) = \sum_{dx=-a}^{a}\sum_{dy=-b}^{b} \omega(dx,dy)f(x+dx,y+dy),
\end{equation}
where $g(x,y)$ is the convoluted matrix, $f(x,y)$ is the original matrix, and $\omega$ is a convolution kernel of dimension $(2a+1,2b+1)$.\footnote{The dimensions of the kernel are typically square and odd, such as $3\times3$ or $5\times5$, giving $dx,dy\in[-1,1]$ or $dx,dy\in[-2,2]$. } For the sake of simplicity, kernel dimensions will be referred to as $a\times b$ where $a$ and $b$ represent the kernel dimensions, and not the half-dimension as would correspond to \cref{eq:convolution}. 

A visualization of the convolution of a matrix (which could represent an image) with a given kernel is provided in \cref{fig:convolution}. Here, the kernel dimensions are $3\times3$. The output matrix has reduced dimensions corresponding to the kernel dimensions. This reduction can be given as 
\begin{equation}
    \left( x_o,y_o \right) = \left( x_i - \left(a - 1\right), x_i - \left( b - 1 \right) \right),
\end{equation}
where $(x_o,y_o)$ are the output dimensions, $(x_i,y_i)$ are the input dimensions, and $a$ and $b$ are the kernel dimensions. In some situations it may not be wanted to reduce the dimensions of the input, and padding the input with zeroes on all sides can be used to combat this. This technique is called \textit{zero-padding} \cite{oshea2015introduction}. 
\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.85\textwidth]{figures/convolution.pdf}
    \caption[Illustration of a 2D discrete convolution]{Illustration of a 2D discrete convolution operation: a) an input matrix of dimension $(9,9)$, where the numbers can e.g. represent intensities in a grayscale image, b) a $3\times3$ convolutional kernel, and c) the resulting convolution of dimension $(7,7)$. This convolution has a stride of 1. Note that the output dimension is smaller than the input dimension. }
    \label{fig:convolution}
\end{figure}

Multiple convolutional kernels can be used in parallel in each convolutional layer. The number of kernels is then referred to as the \textit{number of channels}. 

The \textit{stride} of a convolution is how far the kernel shifts \cite{oshea2015introduction}. In the example given in \cref{fig:convolution}, the stride is 1. If the stride were set to 2, the kernel would shift two units in the matrix for each output. This would mean less overlap between each value in the output, but also further reduction of the output dimensions. 

Often, \textit{pooling layers} are included in \gls{cnn}s. These layers are used to down sample the feature maps after a convolutional layer by applying some pooling function (e.g. max, average, sum) to an area of the feature map, reducing the dimension. This can for instance be a $2\times2$ max pooling layer that looks at a $2\times2$ section of a feature map and replaces it with a single value corresponding to the maximum value of the original section. Pooling layers reduce the dimensions of the feature map corresponding to the size of the pooling (e.g. a $2\times2$ pooling layer reduces both dimensions of a feature map by a factor of $2$). An example is provided in \cref{fig:maxpool}. 

\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.7\textwidth]{figures/maxpool.pdf}
    \caption[Illustration of a max pooling operation]{Illustration of a 2D $2\times2$ max pooling with a stride of 2: a) an input matrix of dimension $(8,8)$, where the numbers can e.g. represent intensities in a grayscale image, and b) the resulting max pooled matrix of dimension $(4,4)$. Every element in b) corresponds to the maximum of four elements in a). }
    \label{fig:maxpool}
\end{figure}

The part of the convolution that a \gls{cnn} learns is the values in the convolutional kernel. Each layer of the \gls{cnn} may have several kernels that are applied in parallel (e.g. 32 kernels applied to the same input). Each kernel is often called a filter. One of the advantages of using convolution in neural networks is the reduction in the number of trainable parameters: a typical convolutional kernel contains $9-49$ parameters (for kernels of dimensions $3\times3$ to $7\times7$), however a fully connected feedforward network may have several thousand parameters for each layer.\footnote{Consider an image of dimension $100\times100$. In a fully connected \gls{ann} there would have to be $100 \cdot 100 = 10^4$ connections from each neuron in one layer to the next layer for a total of $10^{8}$ connections, where each connection has a trainable parameter (not counting the biases). In comparison, if using a \gls{cnn} with 32 channels (or kernels) of dimension $3\times3$ there are only a total of $32 \cdot 3 \cdot 3 = 288$ trainable parameters. } 

\subsection{Encoder-Decoder Network}
\label{sec:ml:types:encoderdecoder}
An encoder-decoder network is a type of \gls{ann} that learns to copy its input to its output \cite{https://doi.org/10.1002/aic.690370209}. It consists of two parts (as the name suggests): an encoder, and a decoder. The task of the encoder is to take the input and encode it into a feature map. The decoder then takes the resulting feature map and decodes it into an output similar to the original input. An illustration of this structure is given in \cref{fig:encoderdecoder}. The encoder's goal is to extract the relevant information from the input, ignoring any signal noise or unwanted data. The decoder then recreates something similar to the original data from the "denoised" feature map. It is common to use \glspl{cnn} as both encoder and decoder, where consecutive layers in the encoder reduce the dimensions of the feature maps and consecutive layers in the decoder increase the dimensions of the feature maps. Encoder-decoder networks have been shown to perform well in many different tasks, such as image segmentation \cite{7803544} and PET image reconstruction \cite{HAGGSTROM2019253}.  

\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.7\textwidth]{figures/encoderdecoder.pdf}
    \caption[Illustration of an encoder-decoder network]{Illustration of the general structure of an encoder-decoder network. It consists of two separable networks, the encoder and the decoder, working together. The input and output layers are of the same dimensions. }
    \label{fig:encoderdecoder}
\end{figure}

In an encoder-decoder network, the encoder and decoder are two separate networks that can work independently of each other. Another similar network structure that builds upon the encoder-decoder is the \textit{U-net} convolutional network, originally proposed for biomedical image segmentation \cite{unet}. It also contains an encoder and a decoder part, however the two networks are not separable as there are skip-connections between layers in the encoder and decoder. In a normal encoder-decoder network, there is first one mapping from the input $X$ to the feature map $L$, $E\colon X \mapsto L$, and then a mapping from the feature map $L$ to the output $Y$, $D\colon L \mapsto Y$. These two mappings are not dependent on each other. In the U-net architecture however,  the mapping in the decoder also depends on the input $X$, making it $D\colon [X+L] \mapsto Y$. 


\subsection{Generative Adversarial Network}
\label{sec:ml:types:gan}
\Glsentrydesc{gan}s (\gls{gan}s) were introduced in \citeyear{goodfellow2014gan} by Goodfellow \textit{et al.} as a novel method of estimating generating models via an adversarial process \cite{goodfellow2014gan}. This type of neural network consists of two separate networks: a generator and a discriminator. The generator, called $G$, captures the distribution of the training data and generates new samples from that distribution, while the discriminator $D$ estimates the probability that a given sample came from the training data (i.e. is a real sample) rather than being a generated sample from $G$. An illustration of the \gls{gan} structure is given in \cref{fig:gan}. 

\begin{figure}[htbp]  
    \centering
    \includegraphics[width=.8\textwidth]{figures/gan.pdf}
    \caption[Illustration of a GAN structure]{Illustration of a \gls{gan} structure. The generator takes a random input and attempts to generate a sample similar to the training data. The discriminator attempts to distinguish a training data sample (i.e. real sample) from a generated sample. The output from the discriminator is used to train the generator to better generate samples similar to the training data, as well as the discriminator to better distinguish between real and generated samples. }
    \label{fig:gan}
\end{figure}

The two networks play a game where they try to minimize their own cost, or error rates, while at the same time maximizing the other network's cost \cite{goodfellow2020gan}.\footnote{\gls{gan}s are designed to reach a Nash equilibrium at which neither of the two networks can reduce its costs without changing the other network's parameters \cite{liu2020tomogan}.} As opposed to normal neural networks that are based on optimization to reduce their error rates, \gls{gan}s are based on game theory \cite{goodfellow2020gan}. 

To generate random samples from the distribution of the training data, a fully trained \gls{gan} is given random noise as input and then maps that to a random sample, such as was done by Zhang \textit{et al.} \cite{zhangsagan}. This allows the network to generate new samples that are similar, but not equal, to the training data. Another common use case for \gls{gan}s is, instead of feeding the network random noise as input, feeding it some data that needs augmentation. This has been used to denoise images and has been shown to be a viable method for image super-resolution \cite{8710893,Ledig_2017_CVPR}. 

\glspl{gan} are generally seen as unsupervised learning algorithms with a supervised loss as part of the training. For a general \gls{gan}, the training data is an unlabeled dataset and the \gls{gan} tries to model a probability distribution of the dataset in order to randomly generate new samples. By generating new samples, it is trivial to apply labels to the original (i.e. real) and generated samples and then use these labels to perform supervised learning to train the discriminator. 

When the input dataset to the \gls{gan} no longer only contains a set to learn the distribution of, but instead the \gls{gan} training process is used to train a generator that takes a non-random input and outputs an augmented version of the input (such as was done by Liu \textit{et al.} \cite{liu2020tomogan}), it can be seen as a supervised learning algorithm.

\section{Training a Neural Network}
The process of tuning all the parameters (i.e. weights and biases) of a neural network is called training. During training, input data from a training dataset is forwards propagated through the network, and the resulting feature map is compared to an expected feature map (e.g. manually labeled data).\footnote{This is what is called supervised learning, as opposed to unsupervised learning where there is no ground truth answer to compare to, instead the network is trying to learn some inherent structure of the data without explicit labels (e.g. clustering). } The difference in these feature maps is calculated using a loss function, and the loss is then backward propagated through the network to update each and every parameter to reduce the loss. 


Generally, the entire training dataset is repeatedly passed through the network multiple times. Each full runthrough of the training dataset is called an \textit{epoch} of training. This however can often introduce a problem: the training dataset can typically not fully fit in the computer memory at once. Therefore it is divided into mini batches, and after each mini batch the weights are adjusted. The propagation of one mini batch is often called one iteration, and thus one epoch consists of several iterations. The size of a mini batch is a tunable parameter, however typically it is in the range of $32-512$ (e.g. 128 in the well-known article by A. Krizhevsky \textit{et al.} \cite{alexnet}).\footnote{There is ongoing research into techniques to increase the batch size by several orders of magnitude as larger batches allow for easier parallelization, however large batch sizes have been shown to cause instability during training \cite{you2017large}. } The size of a mini batch can sometimes also be referred to as the batch size. 

\subsection{Hyperparameters}
During training, the parameters of the neural network are automatically changed, however there are some parameters that are set manually beforehand. These are called hyperparameters \cite{claesen2015hyperparameter}. Some typical hyperparameters are:
\begin{itemize}
    \item Number of layers (i.e. depth of network).
    \item Size (or dimensions) of layers.
    \item Learning rate.
    \item Number of iterations to train the network (or number of epochs).
    \item Mini batch size.
\end{itemize}

The choice of hyperparameters varies with the problem at hand, and is often determined by trial and error. Hyperparameter optimization, allowing automatically tuning hyperparameters for a wide range of scientific problems, is an important topic in machine learning research \cite{hyperparameteroptimizing}.

\subsection{Loss Functions}
\label{sec:ml:training:lossfunctions}
Loss functions are mathematical descriptions that quantify the difference between the feature maps generated by the network, and the expected features (i.e. labels) of the training data. Depending on the problem type, different loss functions may perform better than others, however there are some standard loss functions often used. Some of these, as well as some specific ones used in this thesis, will be presented here. The losses are calculated on a per-pixel basis and summed unless otherwise stated. 

Perhaps the most commonly used loss function is the \gls{mse}. It is closely related to the L2-norm,\footnote{Sometimes the \gls{mse} loss is improperly called the L2-norm, however that is incorrect. The L2-norm can be defined as the square root of \gls{mse}. } and it can be defined as
\begin{equation}
    \label{eq:lossmse}
    L_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^N(Y_i - \hat{Y}_i)^2,
\end{equation}
where $Y$ is the correct (labeled) value,  $\hat{Y}$ is the predicted value, and $N$ is the number of samples. This often performs well, however in cases such as image processing or image super-resolution it has been shown to cause blurring \cite{7797130}.

Another similar loss function is the \gls{mae}, which is closely related to the L1-norm. It can be defined as
\begin{equation}
    \label{eq:lossmae}
    L_{\text{MAE}} = \frac{1}{N} \sum_{i=1}^N |Y_i - \hat{Y}_i|,
\end{equation}
with $Y$ and $\hat{Y}_i$ being the same as previously defined. This loss function does not over-penalize larger errors, and therefore may have different convergence properties than \gls{mse} \cite{7797130}. It has been shown to perform better than \gls{mse} in some image processing cases \cite{7797130,10.1002/mp.13713}. 

A more recently introduced loss function is the log-cosh loss function, defined as \cite{chen2019log}
\begin{equation}
    \label{eq:losslogcosh}
    L_{\text{Log-cosh}} = \frac{1}{a} \sum_{i=1}^N \log ( \cosh ( a ( Y_i - \hat{Y}_i))),
\end{equation}
where $Y$ and $\hat{Y}$ are as previously defined, $\log$ is the logarithm, $\cosh$ is the hyperbolic cosine function, and $a$ is some positive hyperparameter $a \in \mathbb{R}^+$. It behaves similar to \gls{mse} around the origin, and similar to \gls{mae} at other points. It has been shown to perform well in image processing-related tasks \cite{7797130}.

All the aforementioned loss functions rely on pixel-wise losses. Another type of loss function that has been shown to perform well in image processing-related tasks is the use of a \textit{feature space-based loss} \cite{vggloss}. In the case of image processing, it means that the loss is based on measuring the difference in the feature space of the \textit{inference} of a pre-trained network.\footnote{Inference refers to using an already trained network on new data. } Here, the pre-trained VGG network is used to measure a visual loss \cite{simonyan2015deep}. This specific loss function is termed visual loss, or VGG loss, and is defined as \cite{vggloss,liu2020tomogan}
\begin{equation}
    \label{eq:lossvgg}
    L_{\text{VGG}} = \sum_{i=1}^{N} \sum_{j=1}^{W_f} \sum_{k=1}^{H_f} \left(V_{\theta_{\text{VGG}}} (Y_i)_{j,k} - V_{\theta_{\text{VGG}}} (\hat{Y}_i)_{j,k} \right)^2,
\end{equation}
where $Y$ and $\hat{Y}$ are as previously defined, $V_{\theta_{\text{VGG}}}(Y)$ is the VGG feature map representation of image $Y$, and $W_f$ and $H_f$ are the dimensions of the feature maps extracted by the pre-trained VGG network. The VGG network is trained with natural images, specifically the ImageNet dataset \cite{deng2009imagenet}, however it has been shown to work well as a feature extractor for \gls{ct} images \cite{8340157}. 

Specific to \gls{gan}s is the adversarial loss. It is a measure of how well the generator network is able to produce samples that the discriminator network is unable to distinguish from real samples. It can be written as \cite{liu2020tomogan}
\begin{equation}
    \label{eq:lossadv}
    L_{\text{Adv}} = -\frac{1}{N} \sum_{i=1}^{N} D\left(  \hat{Y}_i \right),
\end{equation}
where $\hat{Y}_i$ is the generated guess from the generator network, and $D$ is the discriminator network giving a binary classification $D\left(\hat{Y}_i \right) \in [0,1]$ depending on whether it believes the given image is a real or generated one. Minimizing this loss ensures that the generator network produces samples that have a similar feature map (when extracted by the discriminator network) to real samples, and this process is the basis of \gls{gan}s. 


\subsubsection{Weighted loss}
In practice it is common to use a weighted sum of different loss functions. 
An example containing \gls{mse}, log-cosh, and VGG loss can be given as
\begin{equation}
    \label{eq:weightedloss}
    L_{\text{Total}} = \lambda_{\text{MSE}}L_{\text{MSE}} + \lambda_{\text{Log-cosh}}L_{\text{Log-cosh}} + \lambda_{\text{VGG}}L_{\text{VGG}},
\end{equation}
where $\lambda_N$ is a hyperparameter controlling the weight of $L_N$. 

\subsection{Backpropagation}
Backpropagation is the name given to the process of calculating the needed updates to the parameters of a neural network to reduce the error rate, or loss, of the network. It consists of calculating the partial derivatives of the loss function for each parameter of the network, and then updating them accordingly \cite{Rumelhart1986}. 

The process of passing an input through a network to get some result (i.e. inference) can be seen as forwards propagating through the network. When updating the parameters of the network, a backpropagation algorithm begins by calculating the error of the neurons in the final layer of the network, and then working its way backward layer by layer. For each parameter, its contribution to the total loss of the network is calculated, and the gradient of this contribution is calculated. The backpropagation scheme itself does not update the parameters, but rather it finds what part of the loss corresponds to what parameter. An optimizer is then applied to update the parameters.

\subsection{Optimizers}
To calculate the updates to all parameters, some optimizing method must be used. Two of the most common ones will be briefly introduced here.

\subsubsection{Stochastic Gradient Descent}
The simplest type of optimizer that is often used in training neural networks is the \gls{sgd}. It is an iterative method for optimizing an objective function that has suitable smoothness properties (e.g. differentiability) \cite{stochasticgradientdescent}. It looks at the error in the feature map of the training network (when compared to the labeled ground truth), and calculates an approximation of the gradient needed to update all the weights in the network to reduce the error. Because of the use of mini batches during training of neural networks, the \gls{sgd} method only looks at a randomly selected subset of the whole training data and it is therefore called a stochastic method. The learning rate of \gls{sgd} is the step size used when updating the weights based on the calculated gradient.

\subsubsection{ADAM}
ADAM is an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments \cite{kingma2015adam}. It can be seen as an extension to \gls{sgd}. While \gls{sgd} has one single learning rate, ADAM has one learning rate for each different parameter based on estimates of first and second moments of the gradients. 